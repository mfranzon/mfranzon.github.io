[{"content":"Volumes in Kubernetes could be initialised with several types. One of this is the gitRepo, which is basically an emptyDir volume type, that gets populated by the content of a git repository.\nOne of the most common usage of this is to store static HTML files. Different softwares like Hugo or Jekyll gives you the possibility to get HTML files, starting from a Markdown\u0026rsquo;s one. In this case, an always up-to-date shared volumes could be really useful, It keeps your pod sync with the most recent version of yours static files.\nHow to create a sync pod In the following .yaml template there are the main informations to create a pod with 2 containers.\n  First we create the git-sync container, It pulls every \u0026ldquo;x\u0026rdquo; interval of time (default 3s) from a git repository. The repo to keep synchronised is exported in the GIT_SYNC_REPO variable, which is the same volume shared with the web-server.\n  Second container is the web-server. It just mounts the folder which contains the up-to-date HTML files.\n  apiVersion: v1 kind: Pod metadata: name: $name spec: containers: - name: $containerSyncName image: k8s.gcr.io/git-sync:latest volumeMounts: - name: $volumeNameMd  # shared volume name mountPath: $pathOnTheContainerSync  # path to mount in the container env: - name: GIT_SYNC_REPO value: $volumeHtml - name: $containerServiceName - name: $webServer image: $webServerImage  # typically nginx or traefik volumeMounts: - name: $volumeHtml mountPath: $pathToHtml  # path where are served the html volumes: - name: $volumeHtml gitRepo: repository: $repoToPull revision: $branchRepo directory: . And with private repos ? You can use also a private repository, but in that case you CAN\u0026rsquo;T use the gitRepo volumes. This because It is not configured to have additional configs to pass the SSH key (developers design choice). For this reason, using the git-sync sidecar container is the only way to go.\nTo do that, use a ConfigMap resource, in which set the ssh-key to pull the private repo, than add as additional config to git-sync container the name of the created ConfigMap.\nIn this way you can have an updated folder (which shouldn\u0026rsquo;t be a gitRepo but simply a emptyDir) where all files will be up-to-date.\n","permalink":"https://kubetips.cloud/posts/gitsidecar/","summary":"Volumes in Kubernetes could be initialised with several types. One of this is the gitRepo, which is basically an emptyDir volume type, that gets populated by the content of a git repository.\nOne of the most common usage of this is to store static HTML files. Different softwares like Hugo or Jekyll gives you the possibility to get HTML files, starting from a Markdown\u0026rsquo;s one. In this case, an always up-to-date shared volumes could be really useful, It keeps your pod sync with the most recent version of yours static files.","title":"Using a git repository as volume for a Pod"},{"content":"Pods are, by default, able to connect each other. No matter if they run in the same or different namespaces, no NAT will be performed between pods. Check this article to have more info on pods network.\nTo change this behaviour it is necessary introduce a custom NetworkPolicy. Just to recall the definition:\n NetworkPolicy is a resource which gives you the possibility to specify how a pod communicates with other pods/services in the network.\n Here an example of a very generic NetworkPolicy. It declares, in the namespace you have choose, that no one can connect to any pod into that namespace.\napiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: deny-communication spec: podSelector: If the previous is too strict you can introduce more informations. Assume that in a certain namespace you have a pod for the database, a pod for the web-app and other few pods. Probably, you want that the web-app can communicate with the database, but you do not want to give the same possibility to other pods. What you need is a NetworkPolicy that sets more specific rules.\nHere an example, using 5000 as communication port between web-app and database.\napiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: db-webapp spec: podSelector: matchLabels: app: database ingress: - from: - podSelector: matchLabels: app: webapp ports: - port: 5000 This NetworkPolicy has as subject the app : database resource, which means the pod with the database service. It enforces a communication between the two pods on the port 5000, without using services. More in detail, it create an ingress for the database service which accepts request just from web-app service. If there is also a service associated to those pods, this new rule will be add.\n","permalink":"https://kubetips.cloud/posts/isolatedns/","summary":"Pods are, by default, able to connect each other. No matter if they run in the same or different namespaces, no NAT will be performed between pods. Check this article to have more info on pods network.\nTo change this behaviour it is necessary introduce a custom NetworkPolicy. Just to recall the definition:\n NetworkPolicy is a resource which gives you the possibility to specify how a pod communicates with other pods/services in the network.","title":"NetworkPolicy : Enabling network isolation between Pods in the same Namespace"},{"content":"In the design phase you have to make a lot of right choices to avoid bad surprises during the deploy. One of the most frequent question is: \u0026ldquo;How can I organise my application in Kubernetes to achieve better performances ?\u0026rdquo; Sometimes the correct answer is just make the right decision in splitting and grouping the services in the correct way.\nPods, the resource you always need to Pods are the most used resource in a Kubernetes environment. They contains the running processes, containers to be more precise, one or more, and they could be the actuation of another resource. If you ever asked yourself why we need pods and why we do not use just containers, the answer is the container definition itself. A container is designed to run only a single process; if you decide to run multiple processes on the same container, you have to be sure that the processes in it are running and correct manage their logs because By default, the processes log to the same stdout.\nFor this reason, you need another level of abstraction to wrap, different processes/container that are functional related. A pod keeps the advantage of container isolation giving, the illusion to have all the processes running together.\nPods in Kubernetes can communicate with any other pod. When two pods send network packages between them, they see the IP address because no NAT gateways exists. It does not matter if two pods are in different namespaces or nodes, in both cases they can communicate each other.\n Figure 1. Network between pods. A pod can see other pods and it can be reachable, thanks to a routable IP address for each pod. Kubernetes in Action (2022)Â©  One or multiple containers in a pod ? First of all asking yourself the following questions:\n Do my processes represent a single whole or they are independent ? Do my processes need to run together (some node, that means same resources) or they could run on different hosts ? Do my processes need to scale together or independently ?  Let\u0026rsquo;s try to figure out the problem with a real case scenario. One of the most frequent cases is the web-app application case. The simplest infrastructure could be made from a Front-end (FE), Back-end (BE) and a Database.\nWe can organise this three pieces in different combinations. All in the same pod, three different pods, or two of them in a pod and the other in another pod. To find the best choice we have to consider few aspects. A good way to thinking on it, in the design phase, is make all the possible combinations and see pros and cons.\n  All in the same pod.\nIf all containers are in the same pod, they will always share the same machine. A pod is the unit of a Kubernetes resource, you cannot split the containers into. Another aspect to consider is that, if one of the containers has a failure the pods will send an error and this will hide also the other two services, also they are running correctly. The time of restart will also increase, typically BE and/or FE are update frequently, mostly during development phase. Instead, database is not subject to frequent updates. So, each time you want to see your changes, you should recreate a new pod, this brings a lot of overhead if also other services have to restart.\n  FE-BE in the same pod, Database alone.\nThis just exclude the overhead caused by the database in the init phase and also the pod with the database container could be deploy in a different node, with dedicated resources. Now, the main problem here is that the FE/BE still share the same machine, and, mostly, if they scale, they will scale together. This is a possible choice if the BE/FE are not supposed to be asymmetric, so none of them could have a workload which requires a lot of replicas of it. Suppose to have a BE which take time to process data, it is the perfect case in which you want to scale it, but anytime you also scale the FE, which is an unnecessary overhead.\n  Three different pods.\nGood choice for the case in which FE/BE could have a different workload. Resources can scale independently and can use all the available resources.\n  Keep in mind that not always a container per pod is the best choice, you should make a pros/cons list to have the best organisation for your architecture and do not going crazy to debug it after the deployment!\n","permalink":"https://kubetips.cloud/posts/containersinpod/","summary":"In the design phase you have to make a lot of right choices to avoid bad surprises during the deploy. One of the most frequent question is: \u0026ldquo;How can I organise my application in Kubernetes to achieve better performances ?\u0026rdquo; Sometimes the correct answer is just make the right decision in splitting and grouping the services in the correct way.\nPods, the resource you always need to Pods are the most used resource in a Kubernetes environment.","title":"Make the right choice: one or more Containers in a Pod ?"},{"content":"One of the most used service, to have your Kubernetes cluster deploy in cloud, is the Elastic Kubernetes Service provided by AWS.\nEKS, defined as containers-as-a-service (CaaS), (more details here regarding pricing and general overview) is a managed service that helps to run Kubernetes on AWS. Practically speaking, you do not need to manage the installation of Kubernetes on EC2 instances but you can leave all the configuration stuff to the services provided by EKS.\nConfiguration AWS CLI First of all you have to install and configure the AWS client, here the details for the installation. After that is necessary to add in the .aws folder (which should be created during the aws cli installation) two files:\n  config\naws_access_key_id=[get-from-account-settings] aws_secret_access_key=[get-from-account-settings] region=[aws-region] output=[format, default json]   credentials\naws_access_key_id=[get-from-account-settings] aws_secret_access_key=[get-from-account-settings]   Install kubectl Second step is to install the instrument you will use to administrate the cluster kubectl . Here the instruction to correctly download the right version of kubectl. Keep in mind that, after the installation, a .kube will appear on your home. This will contains the config file to connect with the correspondent cluster.\nAdd required IAM roles IAM roles in AWS environment identify the permissions policies that can be associated to an user. To add the correct permissions to your user, follow this guide. At the end your user should have all the permissions to create an EKS cluster from scratch.\nInstall eksctl Finally, you can install eksctl tool. As you have already done for kubectl, choose here the correct version, according with your OS.\nCreate your first cluster Now it is time to deploy your first cluster, using eksctl, it is trivial. The command is:\neksctl create cluster -f config-cluster.yaml\n#config-cluster.yaml apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: name: cluster-name region: aws-region nodeGroups: - name: ec2-group-name desiredCapacity: # of instances instanceType: instance-type The deployment requires ~15 mins (could be different based on the number and the types of instances you choose). At the end, eksctl write in your .kube/config the specs to connect to the cluster when you use the kubectl tool. When the creation is done, you can interact with your cluster, for example get the system pods with:\nkubectl get pods -A\nThat\u0026rsquo;s all! Have fun with your EKS cluster.\n","permalink":"https://kubetips.cloud/posts/k8scloud/","summary":"One of the most used service, to have your Kubernetes cluster deploy in cloud, is the Elastic Kubernetes Service provided by AWS.\nEKS, defined as containers-as-a-service (CaaS), (more details here regarding pricing and general overview) is a managed service that helps to run Kubernetes on AWS. Practically speaking, you do not need to manage the installation of Kubernetes on EC2 instances but you can leave all the configuration stuff to the services provided by EKS.","title":"Kubernetes in Cloud: easy way to deploy an EKS cluster (AWS)"},{"content":"In this article I want to summarize the most used softwares to deploy a local Kubernetes cluster on your local machine. Having a local deployment of your infrastructure is always a good idea for testing and debugging. There are several platforms you can choose to quickly have your self-hosted Kubernetes.\nMinikube Minikube is probably the most used choice. It can runs in all the major OS and offers an easy installation guide. It is perfect for people that are using multiple OS machines and have some basic familiarity with Kubernetes and Docker. It is a good choice if the infrastructure you want to deploy is not too much complex. Otherwise, you will probably spend too much time looking for the correct minikube configuration, instead of working on your deployment.\nMain features that caracterized Minikube are :\n Supports for all the Kubernetes (good for very retro-compatibility) Cross-platform (Windows, MacOS, Linux) Different containerization systems (Docker, containerd, CRI-O) Add-ons to easily install Kubernetes features and properly configure the deployment Minikube itself could be install in a container as well as on bare metal.  Kind Kind (Kubernetes in Docker) is a CNCF (Cloud Native Computing Foundation) certified conformant Kubernetes installer. It is more devoted to test Kubernetes itself or to have a deeper look on how Kubernetes works under the hood. Kind gives you the possibility to easily install a local cluster using Docker containers as nodes. This makes easy to install, remove, upgrade it unlike Minikube.\nMain aspects are :\n Multi platform (Linux, MacOS, Windows) Multi node cluster (in Minikube you have just one node) No need to configure anything outside of Docker  Microk8s Microk8s is also a CNCF certifided installer for Kubernetes. It is a fully contained platform, all the pieces needed are wrapped in a single package. For this reason it is isolated from other tools of your machine. As for kind, also Microk8s is very easy to install and remove. It is relatively new, so it could be unstable, but seems promising.\nMain points of Microk8s :\n Multi platform BUT on Linux via snap, on MacOs via brew and using an installer for Windows Multi node cluster, each Linux instances connected to the master could be a node of the cluster. Add-ons, as for Minikube there are a set of customizable features.  ","permalink":"https://kubetips.cloud/posts/selfhostedk8s/","summary":"In this article I want to summarize the most used softwares to deploy a local Kubernetes cluster on your local machine. Having a local deployment of your infrastructure is always a good idea for testing and debugging. There are several platforms you can choose to quickly have your self-hosted Kubernetes.\nMinikube Minikube is probably the most used choice. It can runs in all the major OS and offers an easy installation guide.","title":"Kubernetes: solutions to deploy it locally"},{"content":"INTRODUCTION This blog may use cookies, web beacons, tracking pixels, and other tracking technologies when you visit our website [Name of Website.com], including any other media form, media channel, mobile website, or mobile application related or connected thereto (collectively, the âSiteâ) to help customize the Site and improve your experience.\nWe reserve the right to make changes to this Cookie Policy at any time and for any reason. We will alert you about any changes by updating the âLast Updatedâ date of this Cookie Policy. Any changes or modifications will be effective immediately upon posting the updated Cookie Policy on the Site, and you waive the right to receive specific notice of each such change or modification.\nYou are encouraged to periodically review this Cookie Policy to stay informed of updates. You will be deemed to have been made aware of, will be subject to, and will be deemed to have accepted the changes in any revised Cookie Policy by your continued use of the Site after the date such revised Cookie Policy is posted.\nThis cookie policy was created using Termly.\nUSE OF COOKIES A âcookieâ is a string of information which assigns you a unique identifier that we store on your computer. Your browser then provides that unique identifier to use each time you submit a query to the Site. We use cookies on the Site to, among other things, keep track of services you have used, record registration information, record your user preferences, keep you logged into the Site, facilitate purchase procedures, and track the pages you visit. Cookies help us understand how the Site is being used and improve your user experience.\nTYPES OF COOKIES The following types of cookies may be used when you visit the Site:\nAdvertising Cookies Advertising cookies are placed on your computer by advertisers and ad servers in order to display advertisements that are most likely to be of interest to you. These cookies allow advertisers and ad servers to gather information about your visits to the Site and other websites, alternate the ads sent to a specific computer, and track how often an ad has been viewed and by whom. These cookies are linked to a computer and do not gather any personal information about you.\nAnalytics Cookies Analytics cookies monitor how users reached the Site, and how they interact with and move around once on the Site. These cookies let us know what features on the Site are working the best and what features on the Site can be improved.\nOur Cookies Our cookies are âfirst-party cookiesâ, and can be either permanent or temporary. These are necessary cookies, without which the Site won\u0026rsquo;t work properly or be able to provide certain features and functionalities. Some of these may be manually disabled in your browser, but may affect the functionality of the Site.\nPersonalization Cookies Personalization cookies are used to recognize repeat visitors to the Site. We use these cookies to record your browsing history, the pages you have visited, and your settings and preferences each time you visit the Site.\nSecurity Cookies Security cookies help identify and prevent security risks. We use these cookies to authenticate users and protect user data from unauthorized parties Site Management Cookies Site management cookies are used to maintain your identity or session on the Site so that you are not logged off unexpectedly, and any information you enter is retained from page to page. These cookies cannot be turned off individually, but you can disable all cookies in your browser.\nCONTROL OF COOKIES Most browsers are set to accept cookies by default. However, you can remove or reject cookies in your browserâs settings. Please be aware that such action could affect the availability and functionality of the Site.\nFor more information on how to control cookies, check your browser or deviceâs settings for how you can control or reject cookies, or visit the following links:\n Apple Safari Google Chrome Microsoft Edge Microsoft Internet Explorer Mozilla Firefox Opera Android (Chrome) Blackberry Iphone or Ipad (Chrome) Iphone or Ipad (Safari)  In addition, you may opt-out of some third-party cookies through the Network Advertising Initiativeâs Opt-Out Tool.\nOTHER TRACKING TECHNOLOGIES In addition to cookies, we may use web beacons, pixel tags, and other tracking technologies on the Site to help customize the Site and improve your experience. A âweb beaconâ or âpixel tagâ is tiny object or image embedded in a web page or email. They are used to track the number of users who have visited particular pages and viewed emails, and acquire other statistical data. They collect only a limited set of data, such as a cookie number, time and date of page or email view, and a description of the page or email on which they reside. Web beacons and pixel tags cannot be declined. However, you can limit their use by controlling the cookies that interact with them.\nPRIVACY POLICY For more information about how we use information collected by cookies and other tracking technologies, please refer to our Privacy Policy [CLICK HERE]/posted on the Site. This Cookie Policy is part of and is incorporated into our Privacy Policy. By using the Site, you agree to be bound by this Cookie Policy and our Privacy Policy.\n","permalink":"https://kubetips.cloud/cookies/","summary":"INTRODUCTION This blog may use cookies, web beacons, tracking pixels, and other tracking technologies when you visit our website [Name of Website.com], including any other media form, media channel, mobile website, or mobile application related or connected thereto (collectively, the âSiteâ) to help customize the Site and improve your experience.\nWe reserve the right to make changes to this Cookie Policy at any time and for any reason. We will alert you about any changes by updating the âLast Updatedâ date of this Cookie Policy.","title":"COOKIE POLICY"},{"content":"Hi there! I\u0026rsquo;m Marco Franzon and this is KubeTips.\nI would like to have a place in which share what I find interesting and curious using frequently Docker and Kubernetes. As I spend mostly of my time writing Python code and doing DevOps stuff with containers, everyday I face out new bugs or challenges to solve, sometimes it is fun sometimes it is frustrating, but always I learn something new.\nI think on this website as a \u0026ldquo;playbook\u0026rdquo; more than a blog. I will tell about my troubles with Docker, Podman, Singularity, Kubernetes, CRI-O, containerd and some useful tips or software to use to avoid sleepless nights!\nContact Me Want to have a chat with me? Feel free to drop a DM!\nThese are the platforms you can find me on:\n Linkedin: https://www.linkedin.com/in/marco-franzon/ Twitter: @marcofranzon_ap  ","permalink":"https://kubetips.cloud/about/","summary":"Hi there! I\u0026rsquo;m Marco Franzon and this is KubeTips.\nI would like to have a place in which share what I find interesting and curious using frequently Docker and Kubernetes. As I spend mostly of my time writing Python code and doing DevOps stuff with containers, everyday I face out new bugs or challenges to solve, sometimes it is fun sometimes it is frustrating, but always I learn something new.","title":"About Me"},{"content":"The main philosophy of this website is to share the knowledge between developers that have found new solutions for everyday problems.\nIf you want to tell your \u0026ldquo;how to\u0026rdquo;, or you think that an article is incomplete or you can do it better, you are in the right place. Click on Github to start.\n Clone the repo Add your post in ./kubetips/content/posts or modify an existing one.  Posts are written in MarkDown, use this as header in case you are writing a new one: --- title: \u0026quot;Title\u0026quot; date: {{ .Date }} draft: true author : yourname --- If you want to modify an existing one, just add your name in header's authors list Make a Pull Request  And that\u0026rsquo;s all! As soon as possible I will have a look on the new post and for sure merge your contribution.\n","permalink":"https://kubetips.cloud/contribute/","summary":"The main philosophy of this website is to share the knowledge between developers that have found new solutions for everyday problems.\nIf you want to tell your \u0026ldquo;how to\u0026rdquo;, or you think that an article is incomplete or you can do it better, you are in the right place. Click on Github to start.\n Clone the repo Add your post in ./kubetips/content/posts or modify an existing one.  Posts are written in MarkDown, use this as header in case you are writing a new one: --- title: \u0026quot;Title\u0026quot; date: {{ .","title":"How to contribute"}]